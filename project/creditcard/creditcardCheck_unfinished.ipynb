{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'ccc')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAETCAYAAADge6tNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzrCRJHVn2EiSuvt/UsZDQBkcrBUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_classes = pd.value_counts(data[\"Class\"],sort = True).sort_index()\n",
    "count_classes.plot(kind='bar')\n",
    "plt.title('aaa')\n",
    "plt.xlabel('ddd')\n",
    "plt.ylabel('ccc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10     ...           V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794     ...     -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974     ...     -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643     ...      0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952     ...     -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074     ...     -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  normAmount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0    0.244964  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0   -0.342475  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0    1.160686  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0    0.140534  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0   -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data['normAmount'] = StandardScaler().fit_transform(data['Amount'].reshape(-1,1))\n",
    "data = data.drop(['Amount','Time'],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of normal transactions:  0.5\n",
      "Percentage of fraud transactions:  0.5\n",
      "Total number of transactions in resampled data:  984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "D:\\Python\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "X = data.ix[:,data.columns != 'Class']\n",
    "y = data.ix[:,data.columns == 'Class']\n",
    "\n",
    "number_records_fraud = len(data[data.Class == 1])\n",
    "fraud_indices =np.array(data[data.Class == 1].index)\n",
    "\n",
    "normal_indeices = data[data.Class  == 0].index\n",
    "\n",
    "random_normal_indices = np.random.choice(normal_indeices,number_records_fraud,replace=False)\n",
    "random_normal_indices = np.array(random_normal_indices)\n",
    "\n",
    "under_sample_indices = np.concatenate([fraud_indices,random_normal_indices])\n",
    "\n",
    "under_sample_data = data.iloc[under_sample_indices,:]\n",
    "\n",
    "X_undersample = under_sample_data.ix[:,under_sample_data.columns != 'Class']\n",
    "y_undersample = under_sample_data.ix[:,under_sample_data.columns == 'Class']\n",
    "\n",
    "print(\"Percentage of normal transactions: \", len(under_sample_data[under_sample_data.Class == 0])/len(under_sample_data))\n",
    "print(\"Percentage of fraud transactions: \", len(under_sample_data[under_sample_data.Class == 1])/len(under_sample_data))\n",
    "print(\"Total number of transactions in resampled data: \", len(under_sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions train dataset:  199364\n",
      "Number transactions test dataset:  85443\n",
      "Total number of transactions:  284807\n",
      "\n",
      "Number transactions train dataset:  688\n",
      "Number transactions test dataset:  296\n",
      "Total number of transactions:  984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "print(\"Number transactions train dataset: \", len(X_train))\n",
    "print(\"Number transactions test dataset: \", len(X_test))\n",
    "print(\"Total number of transactions: \", len(X_train)+len(X_test))\n",
    "\n",
    "X_train_undersample,X_test_undersample,y_train_undersample,y_test_undersample = train_test_split(X_undersample,\n",
    "                                                                                                 y_undersample,\n",
    "                                                                                                test_size=0.3,\n",
    "                                                                                                random_state=0)\n",
    "print(\"\")\n",
    "print(\"Number transactions train dataset: \", len(X_train_undersample))\n",
    "print(\"Number transactions test dataset: \", len(X_test_undersample))\n",
    "print(\"Total number of transactions: \", len(X_train_undersample)+len(X_test_undersample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选择参数C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold,cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,recall_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printing_Kfold_scores(x_train_data,y_train_data):\n",
    "    fold = KFold(len(y_train_data),5,shuffle=False)\n",
    "    \n",
    "    c_param_range = [0.01,0.1,1,10,100]\n",
    "    \n",
    "    results_table = pd.DataFrame(index=range(len(c_param_range),2),columns=['C_parameter','Mean recall scores'])\n",
    "    results_table['C_parameter'] = c_param_range\n",
    "    \n",
    "    j=0\n",
    "    for c_param in c_param_range:\n",
    "        print('_____________________')\n",
    "        print('C parameter:',c_param)\n",
    "        print('--------------------------------')\n",
    "        print('')\n",
    "        \n",
    "        recall_accs = []\n",
    "        for iteration,indices in enumerate(fold,start=1):\n",
    "            \n",
    "            lr = LogisticRegression(C=c_param,penalty='l1')\n",
    "            \n",
    "            lr.fit(x_train_data.iloc[indices[0],:] , y_train_data.iloc[indices[0],:].values.ravel())\n",
    "            \n",
    "            y_pred_undersample = lr.predict(x_train_data.iloc[indices[1],:].values)\n",
    "            \n",
    "            recall_acc = recall_score(y_train_data.iloc[indices[1],:].values,y_pred_undersample)\n",
    "            recall_accs.append(recall_acc)\n",
    "            print('Iteration ', iteration,': recall score = ', recall_acc)\n",
    "\n",
    "        # The mean value of those recall scores is the metric we want to save and get hold of.\n",
    "        results_table.loc[j,'Mean recall score'] = np.mean(recall_accs)\n",
    "        j += 1\n",
    "        print('')\n",
    "        print('Mean recall score ', np.mean(recall_accs))\n",
    "        print('')\n",
    "\n",
    "    best_c = results_table.loc[results_table['Mean recall score'].idxmax()]['C_parameter']\n",
    "    \n",
    "    # Finally, we can check which C parameter is the best amongst the chosen.\n",
    "    print('*********************************************************************************')\n",
    "    print('Best model to choose from cross validation is with C parameter = ', best_c)\n",
    "    print('*********************************************************************************')\n",
    "    \n",
    "    return best_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________\n",
      "C parameter: 0.01\n",
      "--------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.9315068493150684\n",
      "Iteration  2 : recall score =  0.9178082191780822\n",
      "Iteration  3 : recall score =  0.9830508474576272\n",
      "Iteration  4 : recall score =  0.9594594594594594\n",
      "Iteration  5 : recall score =  0.9696969696969697\n",
      "\n",
      "Mean recall score  0.9523044690214414\n",
      "\n",
      "_____________________\n",
      "C parameter: 0.1\n",
      "--------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.8493150684931506\n",
      "Iteration  2 : recall score =  0.863013698630137\n",
      "Iteration  3 : recall score =  0.9491525423728814\n",
      "Iteration  4 : recall score =  0.9324324324324325\n",
      "Iteration  5 : recall score =  0.9090909090909091\n",
      "\n",
      "Mean recall score  0.900600930203902\n",
      "\n",
      "_____________________\n",
      "C parameter: 1\n",
      "--------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.8767123287671232\n",
      "Iteration  2 : recall score =  0.8904109589041096\n",
      "Iteration  3 : recall score =  0.9830508474576272\n",
      "Iteration  4 : recall score =  0.9459459459459459\n",
      "Iteration  5 : recall score =  0.9242424242424242\n",
      "\n",
      "Mean recall score  0.924072501063446\n",
      "\n",
      "_____________________\n",
      "C parameter: 10\n",
      "--------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.8904109589041096\n",
      "Iteration  2 : recall score =  0.9041095890410958\n",
      "Iteration  3 : recall score =  0.9830508474576272\n",
      "Iteration  4 : recall score =  0.9324324324324325\n",
      "Iteration  5 : recall score =  0.9242424242424242\n",
      "\n",
      "Mean recall score  0.9268492504155379\n",
      "\n",
      "_____________________\n",
      "C parameter: 100\n",
      "--------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.8904109589041096\n",
      "Iteration  2 : recall score =  0.9041095890410958\n",
      "Iteration  3 : recall score =  0.9830508474576272\n",
      "Iteration  4 : recall score =  0.9459459459459459\n",
      "Iteration  5 : recall score =  0.9242424242424242\n",
      "\n",
      "Mean recall score  0.9295519531182406\n",
      "\n",
      "*********************************************************************************\n",
      "Best model to choose from cross validation is with C parameter =  0.01\n",
      "*********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "best_c = printing_Kfold_scores(X_train_undersample,y_train_undersample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 混淆矩阵\n",
    "### Recall = TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#函数生成混淆矩阵图\n",
    "def plot_confusion_matrix(cm,classes,title='Confusion matrix',cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm,interpolation='nearest',cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks,classes,rotation=0)\n",
    "    plt.yticks(tick_marks,classes)\n",
    "    \n",
    "    thresh = cm.max() / 2.\n",
    "    for i,j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n",
    "        plt.text(j,i,cm[i,j] , horizontalalignment='center',color='white' if cm[i,j] > thresh else \"black\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall metric in the testing dataset:  0.9387755102040817\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAEmCAYAAADmw8JdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmmZmOTg0zcxycGiameXw/wFYfnBnML8vwAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "lr = LogisticRegression(C=best_c,penalty='l1')\n",
    "lr.fit(X_train_undersample,y_train_undersample.values.ravel())\n",
    "y_pred_undersample = lr.predict(X_test_undersample.values)\n",
    "\n",
    "#计算混淆矩阵\n",
    "cnf_matrix = confusion_matrix(y_test_undersample,y_pred_undersample)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
    "\n",
    "#绘制非标准化(non-normalized)混淆矩阵\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix,classes=class_names,title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
