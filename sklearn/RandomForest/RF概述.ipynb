{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomForestClassifier 分类\n",
    "##### RandomForestRegressor 回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要调参的参数包括两部分：<br>第一部分是Bagging框架的参数，<br>第二部分是CART决策树的参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数说明：\n",
    "//classsklearn.ensemble.RandomForestClassifier(<br>\n",
    "                            n_estimators=10, #弱学习器的最大迭代次数，或者说最大的弱学习器的个数，默认是10<br>\n",
    "                            criterion='gini', \n",
    "                            max_depth=None,\n",
    "                            min_samples_split=2, \n",
    "                            min_samples_leaf=1, \n",
    "                            min_weight_fraction_leaf=0.0,\n",
    "                            max_features='auto', \n",
    "                            max_leaf_nodes=None, \n",
    "                            min_impurity_split=1e-07,\n",
    "                            bootstrap=True, # 默认True，是否有放回的采样。<br>\n",
    "                            oob_score=False, #默认false,是否采用袋外样本来评估模型的好坏\n",
    "                            n_jobs=1, \n",
    "                            random_state=None, \n",
    "                            verbose=0,\n",
    "                            warm_start=False, \n",
    "                            class_weight=None\n",
    "                            )//\n",
    "                            \n",
    "### RF调参比较简单，因为弱分类器之间没有依赖关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging框架的参数(RF重要的框架参数比较少，主要关注n_estimators，即RF最大的决策树个数。)\n",
    "\n",
    "### n_estimators(子模型数): 弱学习器的最大迭代次数，或者说最大的弱学习器的个数，默认是10.<br>\n",
    "1.n_estimators太小，容易欠拟合，n_estimators太大，又容易过拟合，<br>\n",
    "2.增加“子模型数”（n_estimators）可以明显降低整体模型的方差，且不会对子模型的偏差和方差有任何影响<br>\n",
    "3.模型的准确度会随着“子模型数”的增加而提高，由于减少的是整体模型方差公式的第二项，故准确度的提高有一个上限。在实际应用中，可以以10为单位，考察取值范围在1至201的调参情况。<br>\n",
    "\n",
    "#### 与提升树对比：<br>\n",
    "1.Random Forest:子模型都拥有*较低的偏差*，整体模型的训练过程旨在降低方差，故其需要较少的子模型（n_estimators默认值为10）且子模型不为弱模型（max_depth的默认值为None）<br>\n",
    "2.Gradient Tree Boosting(提升树):子模型都拥有较低的方差，整体模型的训练过程旨在降低偏差，故其需要较多的子模型（n_estimators默认值为100）且子模型为弱模型（max_depth的默认值为3）\n",
    "\n",
    "### bootstrap: # 默认True，是否有放回的采样。<br>\n",
    "### oob_score: #默认false,是否采用袋外样本来评估模型的好坏<br>\n",
    "有放回采样中大约36.8%的没有被采样到的数据，我们常常称之为袋外数据(Out Of Bag, 简称OOB)，这些数据没有参与训练集模型的拟合，因此可以用来检测模型的泛化能力。**个人推荐设置为True**，因为袋外分数反应了一个模型拟合后的泛化能力。对单个模型的参数训练，我们知道可以用cross validation（cv）来进行，但是特别消耗时间，而且对于随机森林这种情况也没有大的必要，所以就用这个数据对决策树模型进行验证，算是一个简单的交叉验证，性能消耗小，但是效果不错。\n",
    "\n",
    "### criterion：\n",
    "即CART树做划分时对特征的评价标准，<br>\n",
    "#### 分类模型和回归模型的损失函数是**不一样**的:\n",
    "分类RF对应的CART分类树默认是基尼系数gini,另一个可选择的标准是信息增益entropy，是用来选择节点的最优特征和切分点的两个准则。<br>\n",
    "回归RF对应的CART回归树默认是均方差mse，另一个可以选择的标准是绝对值差mae。<br>\n",
    "*一般来说选择默认的标准就已经很好的。*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF决策树的参数(要调参的参数基本和GBDT相同)\n",
    "#### max_features: RF划分时考虑的最大特征数。可以使用很多种类型的值:\n",
    "1.**默认是\"None\"**,意味着划分时考虑所有的特征数；<br>\n",
    "2.\"log2\":划分时最多考虑log2N个特征<br>\n",
    "3.\"sqrt\" or \"auto\":划分时最多考虑N−−√N个特征<br>\n",
    "4.整数:考虑的特征绝对数。<br>\n",
    "5.浮点数:考虑特征百分比，即考虑（百分比xN）取整后的特征数，其中N为样本总特征数。<br>\n",
    "##### 一般来说，如果样本特征数不多，比如小于50，我们用默认的\"None\"就可以了，如果特征数非常多，我们可以灵活使用刚才描述的其他取值来控制划分时考虑的最大特征数，以控制决策树的生成时间。\n",
    "\n",
    "#### max_depth: 决策树最大深度。默认为\"None\"，\n",
    "决策树在建立子树的时候不会限制子树的深度, 这样建树时，会使每一个叶节点只有一个类别，或是达到min_samples_split。<br>\n",
    "一般来说，数据少或者特征少的时候可以不管这个值。<br>\n",
    "如果模型样本量多，特征也多的情况下，推荐限制这个最大深度，具体的取值取决于数据的分布。常用的可以取值10-100之间。\n",
    "\n",
    "#### min_samples_split: 内部节点再划分所需最小样本数，默认2。这个值限制了子树继续划分的条件:\n",
    "1.如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分。<br> \n",
    "2.默认是2.如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。\n",
    "\n",
    "#### min_samples_leaf:叶子节点最少样本数。 这个值限制了叶子节点最少的样本数：\n",
    "1.如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝。 默认是1,可以输入最少的样本数的整数，或者最少样本数占样本总数的百分比。<br>\n",
    "2.如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。\n",
    "\n",
    "#### min_weight_fraction_leaf：叶子节点最小的样本权重和。这个值限制了叶子节点所有样本权重和的最小值:\n",
    "1.如果小于这个值，则会和兄弟节点一起被剪枝。 默认是0，就是不考虑权重问题。<br>\n",
    "2.一般来说，如果我们有较多样本有缺失值，或者分类树样本的分布类别偏差很大，就会引入样本权重，这时我们就要注意这个值了。\n",
    "\n",
    "#### max_leaf_nodes: 最大叶子节点数。通过限制最大叶子节点数，可以防止过拟合，默认是\"None”，即不限制最大的叶子节点数。\n",
    "1.如果加了限制，算法会建立在最大叶子节点数内最优的决策树。<br>\n",
    "2.如果特征不多，可以不考虑这个值，但是如果特征分成多的话，可以加以限制，具体的值可以通过交叉验证得到。\n",
    "\n",
    "#### min_impurity_split: 节点划分最小不纯度。这个值限制了决策树的增长:\n",
    "1.如果某节点的不纯度(基于基尼系数，均方差)小于这个阈值，则该节点不再生成子节点，即为叶子节点 。<br>\n",
    "2.一般不推荐改动默认值1e-7。\n",
    "\n",
    "\n",
    "### 上面决策树参数中最重要的包括最大特征数max_features， 最大深度max_depth， 内部节点再划分所需最小样本数min_samples_split和叶子节点最少样本数min_samples_leaf。\n",
    "\n",
    "#### splitter: 随机选择属性\"random\"还是选择不纯度最大\"best\"的属性，建议用默认 best。\n",
    "#### presort:是否对数据进行预分类，以加快拟合中最佳分裂点的发现。默认False，适用于大数据集。\n",
    "1.小数据集使用True,可以加快训练。<br>\n",
    "2.是否预排序,预排序可以加速查找最佳分裂点，对于稀疏数据不管用，Bool，auto：非稀疏数据则预排序，若稀疏数据则不预排序\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 进行预测的几种常用方法\n",
    "predict_proba(x)：给出带有概率值的结果。每个点在所有label（类别）的概率和为1. <br>\n",
    "predict(x)：直接给出预测结果。内部还是调用的predict_proba()，根据概率的结果看哪个类型的预测值最高就是哪个类型。<br> \n",
    "predict_log_proba(x)：和predict_proba基本上一样，只是把结果给做了log()处理。<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest调参实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#导入需要的库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disbursed</th>\n",
       "      <th>Existing_EMI</th>\n",
       "      <th>ID</th>\n",
       "      <th>Loan_Amount_Applied</th>\n",
       "      <th>Loan_Tenure_Applied</th>\n",
       "      <th>Monthly_Income</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Age</th>\n",
       "      <th>EMI_Loan_Submitted_Missing</th>\n",
       "      <th>...</th>\n",
       "      <th>Var2_2</th>\n",
       "      <th>Var2_3</th>\n",
       "      <th>Var2_4</th>\n",
       "      <th>Var2_5</th>\n",
       "      <th>Var2_6</th>\n",
       "      <th>Mobile_Verified_0</th>\n",
       "      <th>Mobile_Verified_1</th>\n",
       "      <th>Source_0</th>\n",
       "      <th>Source_1</th>\n",
       "      <th>Source_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ID000002C20</td>\n",
       "      <td>300000</td>\n",
       "      <td>5</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ID000004E40</td>\n",
       "      <td>200000</td>\n",
       "      <td>2</td>\n",
       "      <td>35000</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ID000007H20</td>\n",
       "      <td>600000</td>\n",
       "      <td>4</td>\n",
       "      <td>22500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ID000008I30</td>\n",
       "      <td>1000000</td>\n",
       "      <td>5</td>\n",
       "      <td>35000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>ID000009J40</td>\n",
       "      <td>500000</td>\n",
       "      <td>2</td>\n",
       "      <td>100000</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Disbursed  Existing_EMI           ID  Loan_Amount_Applied  \\\n",
       "0          0           0.0  ID000002C20               300000   \n",
       "1          0           0.0  ID000004E40               200000   \n",
       "2          0           0.0  ID000007H20               600000   \n",
       "3          0           0.0  ID000008I30              1000000   \n",
       "4          0       25000.0  ID000009J40               500000   \n",
       "\n",
       "   Loan_Tenure_Applied  Monthly_Income  Var4  Var5  Age  \\\n",
       "0                    5           20000     1     0   37   \n",
       "1                    2           35000     3    13   30   \n",
       "2                    4           22500     1     0   34   \n",
       "3                    5           35000     3    10   28   \n",
       "4                    2          100000     3    17   31   \n",
       "\n",
       "   EMI_Loan_Submitted_Missing    ...     Var2_2  Var2_3  Var2_4  Var2_5  \\\n",
       "0                           1    ...          0       0       0       0   \n",
       "1                           0    ...          0       0       0       0   \n",
       "2                           1    ...          0       0       0       0   \n",
       "3                           1    ...          0       0       0       0   \n",
       "4                           1    ...          0       0       0       0   \n",
       "\n",
       "   Var2_6  Mobile_Verified_0  Mobile_Verified_1  Source_0  Source_1  Source_2  \n",
       "0       1                  1                  0         1         0         0  \n",
       "1       1                  0                  1         1         0         0  \n",
       "2       0                  0                  1         0         0         1  \n",
       "3       0                  0                  1         0         0         1  \n",
       "4       0                  0                  1         0         0         1  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#导入数据，顺便看看数据的类别分布\n",
    "train= pd.read_csv('M:/datasets/train_modified.csv',encoding='unicode_escape')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19680\n",
       "1      320\n",
       "Name: Disbursed, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target='Disbursed' # Disbursed的值就是二元分类的输出\n",
    "IDcol= 'ID'\n",
    "train['Disbursed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#接着选择好样本特征和类别输出，样本特征为除去ID和输出类别的列\n",
    "x_columns = [x for x in train.columns if x not in [target,IDcol]]\n",
    "X = train[x_columns]\n",
    "y = train['Disbursed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\envs\\jupyterpy36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98005\n",
      "AUC Score (Train): 0.999833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\envs\\jupyterpy36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:460: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "d:\\python\\envs\\jupyterpy36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:465: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "#不管任何参数，都用默认的，拟合下数据看看\n",
    "rf0 = RandomForestClassifier(oob_score=True, random_state=10)\n",
    "rf0.fit(X,y)\n",
    "print(rf0.oob_score_)\n",
    "y_predprob = rf0.predict_proba(X)[:,1]\n",
    "print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(y,y_predprob))\n",
    "#输出如下：0.98005  AUC Score (Train): 0.999833\n",
    "#可见袋外分数已经很高（理解为袋外数据作为验证集时的准确率，也就是模型的泛化能力），\n",
    "#而且AUC分数也很高（AUC是指从一堆样本中随机抽一个，抽到正样本的概率比抽到负样本的概率 大的可能性）。\n",
    "#相对于GBDT的默认参数输出，RF的默认参数拟合效果对本例要好一些。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### best_score_ ：最佳模型下的分数\n",
    "##### best_params_ ：最佳模型参数\n",
    "~grid_scores_ ：模型不同参数下交叉验证的平均分~\n",
    "##### cv_results_ ： 具体用法模型不同参数下交叉验证的结果\n",
    "##### best_estimator_ : 最佳分类器之所以出现以上问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=8, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=20, min_samples_split=100,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=10, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': range(10, 71, 10)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#首先对n_estimators进行网格搜索\n",
    "param_test1= {'n_estimators':range(10,71,10)}\n",
    "\n",
    "gsearch1= GridSearchCV(\n",
    "    estimator = RandomForestClassifier(\n",
    "        min_samples_split=100,\n",
    "        min_samples_leaf=20,\n",
    "        max_depth=8,\n",
    "        max_features='sqrt' ,\n",
    "        random_state=10\n",
    "    ),\n",
    "    param_grid =param_test1, scoring='roc_auc',cv=5\n",
    "                      )\n",
    "gsearch1.fit(X,y)\n",
    "\n",
    "# gsearch1.cv_results_,\n",
    "# gsearch1.best_params_, \n",
    "# gsearch1.best_score_\n",
    "# grid_scores_在sklearn0.20版本中已被删除，取而代之的是cv_results_。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
