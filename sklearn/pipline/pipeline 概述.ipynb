{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两个好处：\n",
    "\n",
    "1. 直接调用fit和predict方法来对pipeline中的所有算法模型进行训练和预测。\n",
    "\n",
    "2. 可以结合grid search对参数进行选择。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters\n",
    "\n",
    "steps : 步骤：列表(list) 被连接的（名称，变换）元组（实现拟合/变换）的列表，按照它们被连接的顺序，最后一个对象是估计器(estimator)。\n",
    "\n",
    "\n",
    "memory:内存参数,Instance of sklearn.external.joblib.Memory or string, optional (default=None)\n",
    "\n",
    "\n",
    "属性,name_steps:bunch object，具有属性访问权限的字典 只读属性以用户给定的名称访问任何步骤参数。键是步骤名称，值是步骤参数。或者也可以直接通过”.步骤名称”获取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funcution\n",
    "\n",
    "Pipline的方法都是执行各个学习器中对应的方法,如果该学习器没有该方法,会报错\n",
    "\n",
    "假设该Pipline共有n个学习器\n",
    "\n",
    "transform,依次执行各个学习器的transform方法\n",
    "\n",
    "fit,依次对前n-1个学习器执行fit和transform方法,第n个学习器(最后一个学习器)执行fit方法\n",
    "\n",
    "predict,执行第n个学习器的predict方法\n",
    "\n",
    "score,执行第n个学习器的score方法\n",
    "\n",
    "set_params,设置第n个学习器的参数\n",
    "\n",
    "get_param,获取第n个学习器的参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\py35\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/'\n",
    "                 'breast-cancer-wisconsin/wdbc.data', header=None)\n",
    "                                 # Breast Cancer Wisconsin dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = df.values[:, 2:], df.values[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder = LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = encoder.fit_transform(y)\n",
    "encoder.transform(['M', 'B'])\n",
    "#                     array([1, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "操作步骤\n",
    "\n",
    "先用 StandardScaler 对数据集每一列做标准化处理，（是 transformer）\n",
    "\n",
    "再用 PCA 将原始的 30 维度特征压缩的 2 维度，（是 transformer）\n",
    "\n",
    "最后再用模型 LogisticRegression。（是 Estimator）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用 Pipeline 时，输入由元组构成的列表，每个元组第一个值为变量名，元组第二个元素是 sklearn 中的 transformer 或 Estimator。\n",
    "\n",
    "注意中间每一步是 transformer，即它们必须包含 fit 和 transform 方法，或者 fit_transform。 <br>\n",
    "最后一步是一个 Estimator，即最后一步模型要有 fit 方法，可以没有 transform 方法。\n",
    "\n",
    "然后用 Pipeline.fit对训练集进行训练，pipe_lr.fit(X_train, y_train) <br>\n",
    "再直接用 Pipeline.score 对测试集进行预测并评分 pipe_lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\py35\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "pipe_lr = Pipeline([('sc', StandardScaler()),\n",
    "                    ('pca', PCA(n_components=2)),\n",
    "                    ('clf', LogisticRegression(random_state=1))\n",
    "                    ])\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "print('Test accuracy: %.3f' % pipe_lr.score(X_test, y_test))\n",
    "\n",
    "                # Test accuracy: 0.947"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://zhuanlan.zhihu.com/p/42368821"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
