{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-10-01</td>\n",
       "      <td>742</td>\n",
       "      <td>1561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2010-10-02</td>\n",
       "      <td>400</td>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2010-10-03</td>\n",
       "      <td>388</td>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-10-04</td>\n",
       "      <td>762</td>\n",
       "      <td>1474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2010-10-05</td>\n",
       "      <td>821</td>\n",
       "      <td>1639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date  questions  answers\n",
       "0   1  2010-10-01        742     1561\n",
       "1   2  2010-10-02        400      783\n",
       "2   3  2010-10-03        388      771\n",
       "3   4  2010-10-04        762     1474\n",
       "4   5  2010-10-05        821     1639"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#导入数据\n",
    "data_train = pd.read_csv('data_questions/train.csv')\n",
    "data_test  = pd.read_csv('data_questions/test.csv')\n",
    "data_submit= pd.read_csv('data_questions/sample_submit.csv')\n",
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](buzou.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#初始设置\n",
    "beta = [1,1]\n",
    "alpha = 0.2\n",
    "tol_L = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一步\n",
    "![title](huigui.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#对x进行归一化\n",
    "max_x = max(data_train['id']) #2253\n",
    "x = data_train['id'] / max_x\n",
    "y = data_train['questions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数的梯度,梯度就是多元函数的导数\n",
    "![title](gradient.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定义计算梯度的函数\n",
    "def compute_gradient(beta,x,y):\n",
    "    gradient = [0,0]\n",
    "    gradient[0] = 2. * np.mean(beta[0] + beta[1] * x -y)\n",
    "    gradient[1] = 2. * np.mean(x * (beta[0] + beta[1] * x - y))\n",
    "    return np.array(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](disanbu.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#更新beta\n",
    "def update_beta(beta,alpha,gradient):\n",
    "    new_beta = np.array(beta) - alpha * gradient\n",
    "    return new_beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第四步\n",
    "![title](disibu.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#计算RMSE（均方根误差）的函数\n",
    "def rmse(beta,x,y):\n",
    "    squared_error = (beta[0] + beta[1] * x - y) ** 2\n",
    "    result = np.sqrt(np.mean(squared_error))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#开始进行第一次计算\n",
    "gradient = compute_gradient(beta,x,y)\n",
    "loss = rmse(beta,x,y)\n",
    "beta = update_beta(beta,alpha,gradient)\n",
    "loss_new = rmse(beta,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 2 回，均方根误差为 984.983509929\n",
      "第 3 回，均方根误差为 22.6533222671\n",
      "第 4 回，均方根误差为 21.2748710284\n",
      "第 5 回，均方根误差为 20.415520988\n",
      "第 6 回，均方根误差为 19.6980098886\n",
      "第 7 回，均方根误差为 19.0284466732\n",
      "第 8 回，均方根误差为 18.3833051311\n",
      "第 9 回，均方根误差为 17.7565184021\n",
      "第 10 回，均方根误差为 17.1463562977\n",
      "第 11 回，均方根误差为 16.552171702\n",
      "第 12 回，均方根误差为 15.9735937246\n",
      "第 13 回，均方根误差为 15.4103272306\n",
      "第 14 回，均方根误差为 14.8621025985\n",
      "第 15 回，均方根误差为 14.3286626802\n",
      "第 16 回，均方根误差为 13.8097589701\n",
      "第 17 回，均方根误差为 13.3051500539\n",
      "第 18 回，均方根误差为 12.8146006253\n",
      "第 19 回，均方根误差为 12.3378806528\n",
      "第 20 回，均方根误差为 11.8747645954\n",
      "第 21 回，均方根误差为 11.4250306492\n",
      "第 22 回，均方根误差为 10.9884600226\n",
      "第 23 回，均方根误差为 10.5648362456\n",
      "第 24 回，均方根误差为 10.1539445175\n",
      "第 25 回，均方根误差为 9.75557109849\n",
      "第 26 回，均方根误差为 9.36950275011\n",
      "第 27 回，均方根误差为 8.99552622799\n",
      "第 28 回，均方根误差为 8.6334278311\n",
      "第 29 回，均方根误差为 8.28299300997\n",
      "第 30 回，均方根误差为 7.944006036\n",
      "第 31 回，均方根误差为 7.61624973309\n",
      "第 32 回，均方根误差为 7.29950527195\n",
      "第 33 回，均方根误差为 6.9935520268\n",
      "第 34 回，均方根误差为 6.69816749305\n",
      "第 35 回，均方根误差为 6.4131272642\n",
      "第 36 回，均方根误差为 6.13820506502\n",
      "第 37 回，均方根误差为 5.87317283801\n",
      "第 38 回，均方根误差为 5.61780087891\n",
      "第 39 回，均方根误差为 5.37185801717\n",
      "第 40 回，均方根误差为 5.1351118366\n",
      "第 41 回，均方根误差为 4.90732893109\n",
      "第 42 回，均方根误差为 4.68827519039\n",
      "第 43 回，均方根误差为 4.47771611063\n",
      "第 44 回，均方根误差为 4.27541712424\n",
      "第 45 回，均方根误差为 4.08114394436\n",
      "第 46 回，均方根误差为 3.89466291851\n",
      "第 47 回，均方根误差为 3.71574138698\n",
      "第 48 回，均方根误差为 3.54414804132\n",
      "第 49 回，均方根误差为 3.37965327905\n",
      "第 50 回，均方根误差为 3.22202955062\n",
      "第 51 回，均方根误差为 3.07105169545\n",
      "第 52 回，均方根误差为 2.92649726411\n",
      "第 53 回，均方根误差为 2.78814682407\n",
      "第 54 回，均方根误差为 2.65578424706\n",
      "第 55 回，均方根误差为 2.52919697622\n",
      "第 56 回，均方根误差为 2.4081762719\n",
      "第 57 回，均方根误差为 2.29251743502\n",
      "第 58 回，均方根误差为 2.18202000767\n",
      "第 59 回，均方根误差为 2.07648795032\n",
      "第 60 回，均方根误差为 1.97572979605\n",
      "第 61 回，均方根误差为 1.87955878181\n",
      "第 62 回，均方根误差为 1.7877929572\n",
      "第 63 回，均方根误差为 1.70025527167\n",
      "第 64 回，均方根误差为 1.61677364074\n",
      "第 65 回，均方根误差为 1.53718099228\n",
      "第 66 回，均方根误差为 1.46131529398\n",
      "第 67 回，均方根误差为 1.38901956309\n",
      "第 68 回，均方根误差为 1.32014185961\n",
      "第 69 回，均方根误差为 1.25453526427\n",
      "第 70 回，均方根误差为 1.19205784239\n",
      "第 71 回，均方根误差为 1.13257259497\n",
      "第 72 回，均方根误差为 1.07594739822\n",
      "第 73 回，均方根误差为 1.02205493271\n",
      "第 74 回，均方根误差为 0.970772603333\n",
      "第 75 回，均方根误差为 0.921982451147\n",
      "第 76 回，均方根误差为 0.875571058234\n",
      "第 77 回，均方根误差为 0.831429446534\n",
      "第 78 回，均方根误差为 0.789452971642\n",
      "第 79 回，均方根误差为 0.749541212427\n",
      "第 80 回，均方根误差为 0.711597857342\n",
      "第 81 回，均方根误差为 0.675530588161\n",
      "第 82 回，均方根误差为 0.641250961871\n",
      "第 83 回，均方根误差为 0.608674291339\n",
      "第 84 回，均方根误差为 0.577719525387\n",
      "第 85 回，均方根误差为 0.548309128741\n",
      "第 86 回，均方根误差为 0.5203689624\n",
      "第 87 回，均方根误差为 0.49382816479\n",
      "第 88 回，均方根误差为 0.468619034123\n",
      "第 89 回，均方根误差为 0.444676912264\n",
      "第 90 回，均方根误差为 0.421940070416\n",
      "第 91 回，均方根误差为 0.40034959685\n",
      "第 92 回，均方根误差为 0.379849286917\n",
      "第 93 回，均方根误差为 0.360385535489\n",
      "第 94 回，均方根误差为 0.341907232025\n",
      "第 95 回，均方根误差为 0.324365658317\n",
      "第 96 回，均方根误差为 0.307714389073\n",
      "第 97 回，均方根误差为 0.291909195371\n",
      "第 98 回，均方根误差为 0.276907951041\n",
      "第 99 回，均方根误差为 0.262670542009\n",
      "第 100 回，均方根误差为 0.249158778633\n",
      "第 101 回，均方根误差为 0.236336310992\n",
      "第 102 回，均方根误差为 0.224168547171\n",
      "第 103 回，均方根误差为 0.212622574448\n",
      "第 104 回，均方根误差为 0.201667083437\n",
      "第 105 回，均方根误差为 0.191272295048\n",
      "第 106 回，均方根误差为 0.181409890306\n",
      "第 107 回，均方根误差为 0.172052942893\n",
      "第 108 回，均方根误差为 0.163175854411\n",
      "第 109 回，均方根误差为 0.154754292279\n",
      "第 110 回，均方根误差为 0.146765130182\n",
      "第 111 回，均方根误差为 0.13918639103\n",
      "第 112 回，均方根误差为 0.131997192333\n",
      "第 113 回，均方根误差为 0.12517769391\n",
      "第 114 回，均方根误差为 0.118709047897\n",
      "第 115 回，均方根误差为 0.11257335093\n",
      "第 116 回，均方根误差为 0.106753598452\n",
      "第 117 回，均方根误差为 0.101233641076\n",
      "第 118 回，均方根误差为 0.0959981429022\n",
      "系数： 4796.26618876 \n",
      " 最终： 1015.70899949 \n"
     ]
    }
   ],
   "source": [
    "#开始迭代\n",
    "i = 1\n",
    "while np.abs(loss_new - loss) > tol_L:\n",
    "    beta = update_beta(beta,alpha,gradient)\n",
    "    gradient = compute_gradient(beta,x,y)\n",
    "    loss = loss_new\n",
    "    loss_new = rmse(beta,x,y)\n",
    "    i += 1\n",
    "    print('第 %s 回，均方根误差为 %s'%(i,abs(loss_new - loss)))\n",
    "print('系数： %s \\n 最终： %s '%(beta[1],beta[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过118次迭代，达到收敛条件。\n",
    "\n",
    "由于我们对x进行了归一化，上面得到的Coef其实是真实的系数乘以max_x。\n",
    "\n",
    "我们可以还原得到最终的回归系数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终系数：2.12883541445 \n",
      "最终参数：1015.70899949\n"
     ]
    }
   ],
   "source": [
    "print('最终系数：%s \\n最终参数：%s'%(beta[1]/max_x,beta[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终误差：533.598313974\n"
     ]
    }
   ],
   "source": [
    "result = rmse(beta,x,y)\n",
    "print('最终误差：%s'%result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn参数:2.19487084445\n",
      "sklearn参数:936.051219649\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(data_train[['id']],data_train[['questions']])\n",
    "print('sklearn参数:%s'%lr.coef_[0][0])\n",
    "print('sklearn参数:%s'%lr.intercept_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn 平方根误差：531.841307949\n"
     ]
    }
   ],
   "source": [
    "result_sklearn = rmse([936.051219649,2.19487084445],data_train['id'],y)\n",
    "print('sklearn 平方根误差：%s'%result_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
